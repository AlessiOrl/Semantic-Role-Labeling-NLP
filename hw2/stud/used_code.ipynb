{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vars\n"
     ]
    }
   ],
   "source": [
    "from utility import SharedVars, HW2Params34, HW2Dataset12, HW2Dataset34, HW2Params12\n",
    "from hw2.utils import read_dataset\n",
    "import hw2.utils as their_utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from typing import Optional, Union, List, Dict, Any\n",
    "from typing import Tuple, Dict\n",
    "import transformers_embedder as tre\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33malessiorl\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.12.20"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/hw2/stud/wandb/run-20220707_062625-277m6h0y</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href=\"https://wandb.ai/alessiorl/nlp-hw2/runs/277m6h0y\" target=\"_blank\">frosty-morning-68</a></strong> to <a href=\"https://wandb.ai/alessiorl/nlp-hw2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#logger imports\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "wandb_logger = WandbLogger(project=\"nlp-hw2\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul  7 06:26:34 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 515.48.07    Driver Version: 515.48.07    CUDA Version: 11.7     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:09:00.0  On |                  N/A |\r\n",
      "|  0%   47C    P8    14W / 151W |    444MiB /  8192MiB |     46%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1509      G   /usr/lib/xorg/Xorg                 59MiB |\r\n",
      "|    0   N/A  N/A      2292      G   /usr/lib/xorg/Xorg                181MiB |\r\n",
      "|    0   N/A  N/A      2423      G   /usr/bin/gnome-shell               54MiB |\r\n",
      "|    0   N/A  N/A     22925      G   ...021335166955624372,131072       76MiB |\r\n",
      "|    0   N/A  N/A     36103      G   telegram-desktop                    2MiB |\r\n",
      "|    0   N/A  N/A     65141      G   ..._65048.log --shared-files       54MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "mainpath = os.path.join(\"..\", \"..\")\n",
    "datapath = os.path.join(mainpath, \"data\")\n",
    "en_path = os.path.join(datapath, \"EN\")\n",
    "es_path = os.path.join(datapath, \"ES\")\n",
    "fr_path = os.path.join(datapath, \"FR\")\n",
    "dev_name = \"dev.json\"\n",
    "train_name = \"train.json\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "['ES', 'baselines.json', 'EN', 'FR', '.placeholder']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(datapath)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from utilitymine import HW2Dataset34 as HW2Dataset\n",
    "\n",
    "\n",
    "class HW2DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_train_path: str, data_dev_path: str, batch_size: int, data_test_path: str = None) -> None:\n",
    "        super().__init__()\n",
    "        self.data_train_path = data_train_path\n",
    "        self.data_dev_path = data_dev_path\n",
    "        self.data_test_path = data_test_path\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.train_dataset = None\n",
    "        self.validation_dataset = None\n",
    "        self.test_dataset = None\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None) -> None:\n",
    "        if stage == 'fit':\n",
    "            self.train_dataset = HW2Dataset(*read_dataset(self.data_train_path))\n",
    "            self.validation_dataset = HW2Dataset(*read_dataset(self.data_dev_path))\n",
    "        elif stage == 'test':\n",
    "            self.test_dataset = HW2Dataset(*read_dataset(self.data_test_path))\n",
    "\n",
    "    def train_dataloader(self, *args, **kwargs) -> DataLoader:\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True,\n",
    "                          collate_fn=HW2Dataset.collate_fn,\n",
    "                          num_workers=os.cpu_count())\n",
    "\n",
    "    def val_dataloader(self, *args, **kwargs) -> Union[DataLoader, List[DataLoader]]:\n",
    "        return DataLoader(self.validation_dataset, batch_size=self.batch_size, shuffle=False,\n",
    "                          collate_fn=HW2Dataset.collate_fn, num_workers=os.cpu_count())\n",
    "\n",
    "    def test_dataloader(self, *args, **kwargs) -> Union[DataLoader, List[DataLoader]]:\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False,\n",
    "                          collate_fn=HW2Dataset.collate_fn,\n",
    "                          num_workers=os.cpu_count())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def eval34(predictions, labels):\n",
    "    argument_identification_results = their_utils.evaluate_argument_identification(labels, predictions)\n",
    "    argument_classification_results = their_utils.evaluate_argument_classification(labels, predictions)\n",
    "    f1_i, f1_c = argument_identification_results[\"f1\"], argument_classification_results[\"f1\"]\n",
    "    return f1_i, f1_c"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def eval12(predictions, labels):\n",
    "    predicate_identification_results = their_utils.evaluate_predicate_identification(labels, predictions)\n",
    "    predicate_disambiguation_results = their_utils.evaluate_predicate_disambiguation(labels, predictions)\n",
    "    return predicate_identification_results[\"f1\"], predicate_disambiguation_results[\"f1\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class StudentModel12(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, language: str, params: HW2Params12, eval_type: str):\n",
    "        super().__init__()\n",
    "        # load the specific model for the input language\n",
    "        self.language = language\n",
    "        self.params = params\n",
    "\n",
    "        # EMBEDDING LAYERS\n",
    "        self.word_embedder = tre.TransformersEmbedder(params.language_model_name, subword_pooling_strategy=\"scatter\",\n",
    "                                                      layer_pooling_strategy=\"mean\", fine_tune=self.params.fine_tune)\n",
    "\n",
    "        combined_len = self.word_embedder.hidden_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=combined_len, hidden_size=self.params.lstm_hidden_dim,\n",
    "                            num_layers=self.params.lstm_layers, bidirectional=self.params.bidir,\n",
    "                            dropout=self.params.lstm_dropout if self.params.lstm_layers > 1 else 0, batch_first=True)\n",
    "        # Last layers\n",
    "\n",
    "        linears = [(\"lin1\",\n",
    "                    torch.nn.Linear(self.params.lstm_hidden_dim * (2 if self.params.bidir else 1), self.params.hidden)),\n",
    "                   (\"droput\", torch.nn.Dropout(self.params.dropout)), (\"activation\", torch.nn.ReLU()), ]\n",
    "\n",
    "        linears1 = [(\"lin1\", torch.nn.Linear(self.params.hidden, 3)), ]\n",
    "\n",
    "        linears2 = [(\"lin1\", torch.nn.Linear(self.params.hidden, self.params.n_classes12)), ]\n",
    "        self.dual = nn.Sequential(OrderedDict(linears))\n",
    "        self.classificator1 = nn.Sequential(OrderedDict(linears1))\n",
    "\n",
    "        self.classificator2 = nn.Sequential(OrderedDict(linears2))\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.params.learning_rate,\n",
    "                                          weight_decay=self.params.weight_decay)\n",
    "\n",
    "        self.loss_fn_c = torch.nn.CrossEntropyLoss(ignore_index=SharedVars.pred2Index[\"<PAD>\"])\n",
    "        self.loss_fn_i = torch.nn.CrossEntropyLoss(ignore_index=2)\n",
    "\n",
    "        wandb_logger.experiment.config.update(self.params.gethyperparameterdict())\n",
    "\n",
    "\n",
    "    def forward(self, x: dict, y: Optional[dict] = None) -> Dict[str, torch.Tensor]:\n",
    "        inputs = x[\"words\"]\n",
    "        out = self.word_embedder(**inputs)\n",
    "        word_embedding = out.word_embeddings\n",
    "        lstm_out, _ = self.lstm(word_embedding)\n",
    "        out = self.dual(lstm_out)\n",
    "        out1 = self.classificator1(out)\n",
    "        out2 = self.classificator2(out)\n",
    "\n",
    "        out1 = out1.permute(0, 2, 1)\n",
    "        logits1 = torch.softmax(out1, dim=1)\n",
    "\n",
    "        out2 = out2.permute(0, 2, 1)\n",
    "        logits2 = torch.softmax(out2, dim=1)\n",
    "\n",
    "        result = {'logits2': logits2, 'pred2': torch.argmax(logits2, dim=1), 'logits1': logits1,\n",
    "                  'pred1': torch.argmax(logits1, dim=1)}\n",
    "\n",
    "        # compute loss\n",
    "        if y is not None:\n",
    "            labels = y[\"labels\"]\n",
    "            labels1 = y[\"labels1\"]\n",
    "            # while mathematically the CrossEntropyLoss takes as input the probability distributions,\n",
    "            # torch optimizes its computation internally and takes as input the logits instead\n",
    "            loss = self.loss(out2, labels, out1, labels1)\n",
    "            result['loss'] = loss\n",
    "\n",
    "        return result\n",
    "\n",
    "    def loss(self, pred, y, predi, yi):\n",
    "        loss_1 = self.loss_fn_i(predi, yi)\n",
    "        loss_2 = self.loss_fn_c(pred, y)\n",
    "        return (loss_1 + (loss_2 * 9)) / 10\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer\n",
    "\n",
    "    def training_step(self, batch: Tuple[torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        forward_output = self.forward(*batch)\n",
    "\n",
    "        self.log('train_loss', forward_output['loss'], prog_bar=False, batch_size=self.params.batch_size)\n",
    "\n",
    "        return forward_output['loss']\n",
    "\n",
    "    def validation_step(self, batch: Tuple[torch.Tensor], batch_idx: int):\n",
    "        sentences_len = batch[0][\"words\"][\"sentence_lengths\"]\n",
    "        forward_output = self.forward(*batch)\n",
    "        pred = dict()\n",
    "        label = dict()\n",
    "        for i, v in enumerate(batch[1][\"sentence_ids\"]):\n",
    "            cls_index_shift = 1 if batch[0][\"bool_cls\"] else 0\n",
    "\n",
    "            #also remove pad\n",
    "            preds = HW2Dataset12.decode_labels(\n",
    "                (forward_output[\"pred2\"][i][cls_index_shift:sentences_len[i] - (2 - cls_index_shift)]).tolist())\n",
    "\n",
    "            labels = HW2Dataset12.decode_labels(\n",
    "                (batch[1][\"labels\"][i][cls_index_shift:sentences_len[i] - (2 - cls_index_shift)]).tolist())\n",
    "\n",
    "            pred[v] = {\"predicates\": preds}\n",
    "            label[v] = {\"predicates\": labels}\n",
    "        try:\n",
    "            f1_i, f1_c = eval12(pred, label)\n",
    "        except ArithmeticError:\n",
    "            f1_i = f1_c = 0.0\n",
    "\n",
    "        self.log('val_f1_1', f1_i, prog_bar=False, batch_size=self.params.batch_size)\n",
    "        self.log('val_f1_2', f1_c, prog_bar=True, batch_size=self.params.batch_size)\n",
    "        self.log('val_loss', forward_output['loss'], prog_bar=True, batch_size=self.params.batch_size)\n",
    "\n",
    "    def predict(self, sentence):\n",
    "        \"\"\"\n",
    "        --> !!! STUDENT: implement here your predict function !!! <--\n",
    "\n",
    "        Args:\n",
    "                sentence: a dictionary that represents an input sentence, for example:\n",
    "                        - If you are doing argument identification + argument classification:\n",
    "                                {\n",
    "                                        \"words\":\n",
    "                                                [  \"In\",  \"any\",  \"event\",  \",\",  \"Mr.\",  \"Englund\",  \"and\",  \"many\",  \"others\",  \"say\",  \"that\",  \"the\",  \"easy\",  \"gains\",  \"in\",  \"narrowing\",  \"the\",  \"trade\",  \"gap\",  \"have\",  \"already\",  \"been\",  \"made\",  \".\"  ]\n",
    "                                        \"lemmas\":\n",
    "                                                [\"in\", \"any\", \"event\", \",\", \"mr.\", \"englund\", \"and\", \"many\", \"others\", \"say\", \"that\", \"the\", \"easy\", \"gain\", \"in\", \"narrow\", \"the\", \"trade\", \"gap\", \"have\", \"already\", \"be\", \"make\",  \".\"],\n",
    "                                        \"predicates\":\n",
    "                                                [\"_\", \"_\", \"_\", \"_\", \"_\", \"_\", \"_\", \"_\", \"_\", \"AFFIRM\", \"_\", \"_\", \"_\", \"_\", \"_\", \"REDUCE_DIMINISH\", \"_\", \"_\", \"_\", \"_\", \"_\", \"_\", \"MOUNT_ASSEMBLE_PRODUCE\", \"_\" ],\n",
    "                                },\n",
    "                        - If you are doing predicate disambiguation + argument identification + argument classification:\n",
    "                                {\n",
    "                                        \"words\": [...], # SAME AS BEFORE\n",
    "                                        \"lemmas\": [...], # SAME AS BEFORE\n",
    "                                        \"predicates\":\n",
    "                                                [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0 ],\n",
    "                                },\n",
    "                        - If you are doing predicate identification + predicate disambiguation + argument identification + argument classification:\n",
    "                                {\n",
    "                                        \"words\": [...], # SAME AS BEFORE\n",
    "                                        \"lemmas\": [...], # SAME AS BEFORE\n",
    "                                        # NOTE: you do NOT have a \"predicates\" field here.\n",
    "                                },\n",
    "\n",
    "        Returns:\n",
    "                A dictionary with your predictions:\n",
    "                        - If you are doing argument identification + argument classification:\n",
    "                                {\n",
    "                                        \"roles\": list of lists, # A list of roles for each predicate in the sentence.\n",
    "                                }\n",
    "                        - If you are doing predicate disambiguation + argument identification + argument classification:\n",
    "                                {\n",
    "                                        \"predicates\": list, # A list with your predicted predicate senses, one for each token in the input sentence.\n",
    "                                        \"roles\": dictionary of lists, # A list of roles for each pre-identified predicate (index) in the sentence.\n",
    "                                }\n",
    "                        - If you are doing predicate identification + predicate disambiguation + argument identification + argument classification:\n",
    "                                {\n",
    "                                        \"predicates\": list, # A list of predicate senses, one for each token in the sentence, null (\"_\") included.\n",
    "                                        \"roles\": dictionary of lists, # A list of roles for each predicate (index) you identify in the sentence.\n",
    "                                }\n",
    "        \"\"\"\n",
    "        sentence_dataset = HW2Dataset12(sentence, hassentenceid=False)\n",
    "        sentence_dataloader = DataLoader(sentence_dataset, batch_size=self.params.batch_size, shuffle=False,\n",
    "                                         collate_fn=HW2Dataset12.collate_fn, num_workers=os.cpu_count())\n",
    "        pred2 = dict()\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in sentence_dataloader:\n",
    "                sentences_len = batch[0][\"words\"][\"sentence_lengths\"]\n",
    "                forward_output = self.forward(batch[0])\n",
    "                for i, v in enumerate(batch[1][\"sentence_ids\"]):\n",
    "                    cls_index_shift = 1 if batch[0][\"bool_cls\"] else 0\n",
    "                    # also remove pad\n",
    "                    preds2 = HW2Dataset12.decode_labels(\n",
    "                        (forward_output[\"pred2\"][i][cls_index_shift:sentences_len[i] - (2 - cls_index_shift)]).tolist())\n",
    "                    pred2[v] = {\"predicates\": preds2}\n",
    "\n",
    "        return pred2\n",
    "\n",
    "\n",
    "class StudentModel34(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, language: str, params: HW2Params34, eval_type=\"34\"):\n",
    "        super().__init__()\n",
    "        # load the specific model for the input language\n",
    "        self.language = language\n",
    "        self.params = params\n",
    "\n",
    "        # EMBEDDING LAYERS\n",
    "        self.word_embedder = tre.TransformersEmbedder(params.language_model_name, subword_pooling_strategy=\"scatter\",\n",
    "                                                      layer_pooling_strategy=\"mean\", fine_tune=self.params.fine_tune)\n",
    "\n",
    "        combined_len = (self.word_embedder.hidden_size * 2)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=combined_len, hidden_size=self.params.lstm_hidden_dim,\n",
    "                            num_layers=self.params.lstm_layers, bidirectional=self.params.bidir,\n",
    "                            dropout=self.params.lstm_dropout if self.params.lstm_layers > 1 else 0, batch_first=True)\n",
    "        # Last layers\n",
    "\n",
    "        linears = [(\"lin1\",\n",
    "                    torch.nn.Linear(self.params.lstm_hidden_dim * (2 if self.params.bidir else 1), self.params.hidden)),\n",
    "                   (\"activation\", nn.ReLU()), (\"lin2\", torch.nn.Linear(self.params.hidden, self.params.n_classes34)), ]\n",
    "\n",
    "        self.classificator = nn.Sequential(OrderedDict(linears))\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.params.learning_rate,\n",
    "                                          weight_decay=self.params.weight_decay)\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss(ignore_index=SharedVars.semanticRoles2Index[\"<PAD>\"])\n",
    "\n",
    "        wandb_logger.experiment.config.update(self.params.gethyperparameterdict())\n",
    "\n",
    "\n",
    "    def forward(self, x: dict, y: Optional[dict] = None) -> Dict[str, torch.Tensor]:\n",
    "        inputs = x[\"words\"]\n",
    "        preds = x[\"p_indexs\"]\n",
    "\n",
    "        out = self.word_embedder(**inputs)\n",
    "\n",
    "        word_embedding = out.word_embeddings\n",
    "\n",
    "        pred_embedding = torch.unsqueeze(word_embedding[range(len(preds)), preds, :], dim=1)\n",
    "        pred_embedding = pred_embedding.expand(-1, word_embedding.shape[1], -1)\n",
    "        combined_embeddings = torch.cat((word_embedding, pred_embedding), 2)\n",
    "\n",
    "        lstm_out, _ = self.lstm(combined_embeddings)\n",
    "\n",
    "        out = self.classificator(lstm_out)\n",
    "\n",
    "        out = out.permute(0, 2, 1)\n",
    "        logits = torch.softmax(out, dim=1)\n",
    "\n",
    "        result = {'logits': logits, 'pred': torch.argmax(logits, dim=1)}\n",
    "        # compute loss\n",
    "        if y is not None:\n",
    "            labels = y[\"labels\"]\n",
    "            # while mathematically the CrossEntropyLoss takes as input the probability distributions,\n",
    "            # torch optimizes its computation internally and takes as input the logits instead\n",
    "            loss = self.loss(out, labels)\n",
    "            result['loss'] = loss\n",
    "\n",
    "        return result\n",
    "\n",
    "    def loss(self, pred, y):\n",
    "        return self.loss_fn(pred, y)\n",
    "\n",
    "    def training_step(self, batch: Tuple[torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
    "        forward_output = self.forward(*batch)\n",
    "\n",
    "        #self.log('train_loss_3', forward_output['loss'], prog_bar=True, batch_size=self.params.batch_size)\n",
    "        self.log('train_loss_4', forward_output['loss'], prog_bar=False, batch_size=self.params.batch_size)\n",
    "\n",
    "        return forward_output['loss']\n",
    "\n",
    "    def validation_step(self, batch: Tuple[torch.Tensor], batch_idx: int):\n",
    "        sentences_len = batch[0][\"words\"][\"sentence_lengths\"]\n",
    "        forward_output = self.forward(*batch)\n",
    "        pred = dict()\n",
    "        roles = dict()\n",
    "        for i, v in enumerate(batch[1][\"sentence_ids\"]):\n",
    "            pred_index = batch[0][\"p_indexs\"][i]\n",
    "            cls_index_shift = 1 if batch[0][\"bool_cls\"] else 0\n",
    "            #also remove pad\n",
    "            proles = HW2Dataset34.decode_labels(\n",
    "                (forward_output[\"pred\"][i][cls_index_shift:sentences_len[i] - (2 - cls_index_shift)]).tolist())\n",
    "\n",
    "            lroles = HW2Dataset34.decode_labels(\n",
    "                (batch[1][\"labels\"][i][cls_index_shift:sentences_len[i] - (2 - cls_index_shift)]).tolist())\n",
    "\n",
    "            pred[v] = {\"roles\": {pred_index: proles}}\n",
    "            roles[v] = {\"roles\": {pred_index: lroles}}\n",
    "        try:\n",
    "            f1_i, f1_c = eval34(pred, roles)\n",
    "        except ArithmeticError:\n",
    "            f1_i = f1_c = 0.0\n",
    "\n",
    "        self.log('val_f1_3', f1_i, prog_bar=False, batch_size=self.params.batch_size)\n",
    "        self.log('val_f1_4', f1_c, prog_bar=True, batch_size=self.params.batch_size)\n",
    "        #self.log('val_loss_3', forward_output['loss'], prog_bar=True, batch_size=self.params.batch_size)\n",
    "        self.log('val_loss_4', forward_output['loss'], prog_bar=True, batch_size=self.params.batch_size)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer\n",
    "\n",
    "    def predict(self, sentence):\n",
    "        \"\"\"\n",
    "        --> !!! STUDENT: implement here your predict function !!! <--\n",
    "\n",
    "        Args:\n",
    "                sentence: a dictionary that represents an input sentence, for example:\n",
    "                        - If you are doing argument identification + argument classification:\n",
    "                                {\n",
    "                                        \"words\":\n",
    "                                                [  \"In\",  \"any\",  \"event\",  \",\",  \"Mr.\",  \"Englund\",  \"and\",  \"many\",  \"others\",  \"say\",  \"that\",  \"the\",  \"easy\",  \"gains\",  \"in\",  \"narrowing\",  \"the\",  \"trade\",  \"gap\",  \"have\",  \"already\",  \"been\",  \"made\",  \".\"  ]\n",
    "                                        \"lemmas\":\n",
    "                                                [\"in\", \"any\", \"event\", \",\", \"mr.\", \"englund\", \"and\", \"many\", \"others\", \"say\", \"that\", \"the\", \"easy\", \"gain\", \"in\", \"narrow\", \"the\", \"trade\", \"gap\", \"have\", \"already\", \"be\", \"make\",  \".\"],\n",
    "                                        \"predicates\":\n",
    "                                                [\"_\", \"_\", \"_\", \"_\", \"_\", \"_\", \"_\", \"_\", \"_\", \"AFFIRM\", \"_\", \"_\", \"_\", \"_\", \"_\", \"REDUCE_DIMINISH\", \"_\", \"_\", \"_\", \"_\", \"_\", \"_\", \"MOUNT_ASSEMBLE_PRODUCE\", \"_\" ],\n",
    "                                },\n",
    "                        - If you are doing predicate disambiguation + argument identification + argument classification:\n",
    "                                {\n",
    "                                        \"words\": [...], # SAME AS BEFORE\n",
    "                                        \"lemmas\": [...], # SAME AS BEFORE\n",
    "                                        \"predicates\":\n",
    "                                                [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0 ],\n",
    "                                },\n",
    "                        - If you are doing predicate identification + predicate disambiguation + argument identification + argument classification:\n",
    "                                {\n",
    "                                        \"words\": [...], # SAME AS BEFORE\n",
    "                                        \"lemmas\": [...], # SAME AS BEFORE\n",
    "                                        # NOTE: you do NOT have a \"predicates\" field here.\n",
    "                                },\n",
    "\n",
    "        Returns:\n",
    "                A dictionary with your predictions:\n",
    "                        - If you are doing argument identification + argument classification:\n",
    "                                {\n",
    "                                        \"roles\": list of lists, # A list of roles for each predicate in the sentence.\n",
    "                                }\n",
    "                        - If you are doing predicate disambiguation + argument identification + argument classification:\n",
    "                                {\n",
    "                                        \"predicates\": list, # A list with your predicted predicate senses, one for each token in the input sentence.\n",
    "                                        \"roles\": dictionary of lists, # A list of roles for each pre-identified predicate (index) in the sentence.\n",
    "                                }\n",
    "                        - If you are doing predicate identification + predicate disambiguation + argument identification + argument classification:\n",
    "                                {\n",
    "                                        \"predicates\": list, # A list of predicate senses, one for each token in the sentence, null (\"_\") included.\n",
    "                                        \"roles\": dictionary of lists, # A list of roles for each predicate (index) you identify in the sentence.\n",
    "                                }\n",
    "        \"\"\"\n",
    "\n",
    "        sentence_dataset = HW2Dataset34(sentence, hassentenceid=False)\n",
    "        sentence_dataloader = DataLoader(sentence_dataset, batch_size=self.params.batch_size, shuffle=False,\n",
    "                                         collate_fn=HW2Dataset34.collate_fn, num_workers=os.cpu_count())\n",
    "        pred = dict()\n",
    "        self.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in sentence_dataloader:\n",
    "                sentences_len = batch[0][\"words\"][\"sentence_lengths\"]\n",
    "                forward_output = self.forward(batch[0])\n",
    "\n",
    "                for i, v in enumerate(batch[1][\"sentence_ids\"]):\n",
    "                    pred_index = batch[0][\"p_indexs\"][i].item()\n",
    "                    cls_index_shift = 1 if batch[0][\"bool_cls\"] else 0\n",
    "                    proles = HW2Dataset34.decode_labels(\n",
    "                        (forward_output[\"pred\"][i][cls_index_shift:sentences_len[i] - (2 - cls_index_shift)]).tolist())\n",
    "                    pred[pred_index] = proles\n",
    "\n",
    "        return {\"roles\": pred}\n",
    "\n",
    "class StudentModel1234(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, language: str, model12: StudentModel12, model34: StudentModel34):\n",
    "        super().__init__()\n",
    "        self.model12 = model12\n",
    "        self.model34 = model34\n",
    "\n",
    "    def predict(self, sentence):\n",
    "        out12 = self.model12.predict(sentence)\n",
    "\n",
    "        sentence[\"predicates\"] = out12.popitem()[1][\"predicates\"]\n",
    "        out34 = self.model34.predict(sentence)\n",
    "\n",
    "        result = {\"predicates\": sentence[\"predicates\"], \"roles\": out34[\"roles\"]}\n",
    "\n",
    "        return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "early_stopping = pl.callbacks.EarlyStopping(monitor='val_f1_4',\n",
    "                                            # the value that will be evaluated to activate the early stopping of the model.\n",
    "                                            patience=3,\n",
    "                                            # the number of consecutive attempts that the model has to raise (or lower depending on the metric used) to raise the \"monitor\" value.\n",
    "                                            verbose=True,  # whether to log or not information in the console.\n",
    "                                            mode='max',\n",
    "                                            # wheter we want to maximize (max) or minimize the \"monitor\" value.\n",
    "                                            )\n",
    "\n",
    "check_point_callback = pl.callbacks.ModelCheckpoint(monitor='val_f1_4',\n",
    "                                                    # the value that we want to use for model selection.\n",
    "                                                    verbose=True,  # whether to log or not information in the console.\n",
    "                                                    save_top_k=3,  # the number of checkpoints we want to store.\n",
    "                                                    mode='max',\n",
    "                                                    # wheter we want to maximize (max) or minimize the \"monitor\" value.\n",
    "                                                    dirpath=os.path.join(mainpath, 'experiments/hw2models'),\n",
    "                                                    # output directory path\n",
    "                                                    filename=wandb_logger.experiment.name + '-{epoch}-{val_f1_4:.4f}'\n",
    "                                                    # the prefix on the checkpoint values. Metrics store by the trainer can be used to dynamically change the name.\n",
    "                                                    )\n",
    "\n",
    "hw2_dm = HW2DataModule(data_train_path=os.path.join(en_path, train_name), data_dev_path=os.path.join(en_path, dev_name),\n",
    "                       data_test_path=os.path.join(en_path, dev_name), batch_size=HW2Params34.batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "hw2_dm.setup('fit')\n",
    "train_dataloader = hw2_dm.train_dataloader()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = StudentModel34(language=\"EN\", params=HW2Params34(\"gpu\"), eval_type=\"34\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# the PyTorch Lightning Trainer\n",
    "trainer = pl.Trainer(max_epochs=HW2Params34.epochs,  # maximum number of epochs.\n",
    "                     gpus=HW2Params34.gpus,  # the number of gpus we have at our disposal.\n",
    "                     callbacks=[early_stopping, check_point_callback],  # the callback we want our trainer to use.\n",
    "                     logger=wandb_logger,\n",
    "                     )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orlando/anaconda3/envs/nlp2022-hw2/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: UserWarning: Checkpoint directory /home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                 | Params\n",
      "-------------------------------------------------------\n",
      "0 | word_embedder | TransformersEmbedder | 278 M \n",
      "1 | lstm          | LSTM                 | 1.7 M \n",
      "2 | classificator | Sequential           | 36.6 K\n",
      "3 | loss_fn       | CrossEntropyLoss     | 0     \n",
      "-------------------------------------------------------\n",
      "279 M     Trainable params\n",
      "0         Non-trainable params\n",
      "279 M     Total params\n",
      "1,119.145 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77651cf6393a4e3c9a3b1cd34926421b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14808404a97841f1bb38f8f009dd22db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f56e51f73ca4aed90308c8e5b484b46"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1_4 improved. New best score: 0.000\n",
      "Epoch 0, global step 786: 'val_f1_4' reached 0.00000 (best 0.00000), saving model to '/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models/frosty-morning-68-epoch=0-val_f1_4=0.0000.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dbcda301dd034b649a20af9dabb1f0e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1_4 improved by 0.258 >= min_delta = 0.0. New best score: 0.258\n",
      "Epoch 1, global step 1572: 'val_f1_4' reached 0.25809 (best 0.25809), saving model to '/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models/frosty-morning-68-epoch=1-val_f1_4=0.2581.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "257023de4ecc4b3595fd64cf7edba587"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1_4 improved by 0.160 >= min_delta = 0.0. New best score: 0.418\n",
      "Epoch 2, global step 2358: 'val_f1_4' reached 0.41843 (best 0.41843), saving model to '/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models/frosty-morning-68-epoch=2-val_f1_4=0.4184.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "670d48bbbe394b24b56c815753c14c2e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1_4 improved by 0.079 >= min_delta = 0.0. New best score: 0.498\n",
      "Epoch 3, global step 3144: 'val_f1_4' reached 0.49779 (best 0.49779), saving model to '/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models/frosty-morning-68-epoch=3-val_f1_4=0.4978.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b9ff67a5b524cab8d7d10c16784bf67"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1_4 improved by 0.074 >= min_delta = 0.0. New best score: 0.572\n",
      "Epoch 4, global step 3930: 'val_f1_4' reached 0.57198 (best 0.57198), saving model to '/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models/frosty-morning-68-epoch=4-val_f1_4=0.5720.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee5434a1055c44af963ec213397b22dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1_4 improved by 0.091 >= min_delta = 0.0. New best score: 0.663\n",
      "Epoch 5, global step 4716: 'val_f1_4' reached 0.66304 (best 0.66304), saving model to '/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models/frosty-morning-68-epoch=5-val_f1_4=0.6630.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ecaa3d66a324c80aa0872882a83c4d0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1_4 improved by 0.045 >= min_delta = 0.0. New best score: 0.708\n",
      "Epoch 6, global step 5502: 'val_f1_4' reached 0.70772 (best 0.70772), saving model to '/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models/frosty-morning-68-epoch=6-val_f1_4=0.7077.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb42f0533af74a518fd81bfae40b1a17"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1_4 improved by 0.034 >= min_delta = 0.0. New best score: 0.742\n",
      "Epoch 7, global step 6288: 'val_f1_4' reached 0.74202 (best 0.74202), saving model to '/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models/frosty-morning-68-epoch=7-val_f1_4=0.7420.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "98f3269dae4048f9ad074a60a2381ebb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1_4 improved by 0.022 >= min_delta = 0.0. New best score: 0.764\n",
      "Epoch 8, global step 7074: 'val_f1_4' reached 0.76382 (best 0.76382), saving model to '/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models/frosty-morning-68-epoch=8-val_f1_4=0.7638.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb0d18be8ad34cc08805946c093cd97b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1_4 improved by 0.012 >= min_delta = 0.0. New best score: 0.776\n",
      "Epoch 9, global step 7860: 'val_f1_4' reached 0.77586 (best 0.77586), saving model to '/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models/frosty-morning-68-epoch=9-val_f1_4=0.7759.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09f7ad48b1da4bf097578eeebc113aec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1_4 improved by 0.011 >= min_delta = 0.0. New best score: 0.787\n",
      "Epoch 10, global step 8646: 'val_f1_4' reached 0.78694 (best 0.78694), saving model to '/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models/frosty-morning-68-epoch=10-val_f1_4=0.7869.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a8979b042f84666988e8cbbccd8fcb8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1_4 improved by 0.004 >= min_delta = 0.0. New best score: 0.791\n",
      "Epoch 11, global step 9432: 'val_f1_4' reached 0.79131 (best 0.79131), saving model to '/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models/frosty-morning-68-epoch=11-val_f1_4=0.7913.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a87f87d57d594ca389b2eec60aaf80c2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1_4 improved by 0.014 >= min_delta = 0.0. New best score: 0.805\n",
      "Epoch 12, global step 10218: 'val_f1_4' reached 0.80510 (best 0.80510), saving model to '/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models/frosty-morning-68-epoch=12-val_f1_4=0.8051.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "474ce077b808490eb3e77f517d70e307"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 11004: 'val_f1_4' reached 0.80147 (best 0.80510), saving model to '/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models/frosty-morning-68-epoch=13-val_f1_4=0.8015.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e30838187bed41dab8c92323c7b85baf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1_4 improved by 0.005 >= min_delta = 0.0. New best score: 0.810\n",
      "Epoch 14, global step 11790: 'val_f1_4' reached 0.81013 (best 0.81013), saving model to '/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models/frosty-morning-68-epoch=14-val_f1_4=0.8101.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7415c3478f564ec8af7564c3525a7f24"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1_4 improved by 0.001 >= min_delta = 0.0. New best score: 0.811\n",
      "Epoch 15, global step 12576: 'val_f1_4' reached 0.81071 (best 0.81071), saving model to '/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models/frosty-morning-68-epoch=15-val_f1_4=0.8107.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e04fbebd393d41bb8c7926fa6903bbbc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1_4 improved by 0.001 >= min_delta = 0.0. New best score: 0.812\n",
      "Epoch 16, global step 13362: 'val_f1_4' reached 0.81160 (best 0.81160), saving model to '/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models/frosty-morning-68-epoch=16-val_f1_4=0.8116.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e2374b7b6d0d46869085b24d4a6b330b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1_4 improved by 0.003 >= min_delta = 0.0. New best score: 0.815\n",
      "Epoch 17, global step 14148: 'val_f1_4' reached 0.81465 (best 0.81465), saving model to '/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models/frosty-morning-68-epoch=17-val_f1_4=0.8147.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33001aa31f154cf3ac35aa5e4210e55d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1_4 improved by 0.004 >= min_delta = 0.0. New best score: 0.819\n",
      "Epoch 18, global step 14934: 'val_f1_4' reached 0.81881 (best 0.81881), saving model to '/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models/frosty-morning-68-epoch=18-val_f1_4=0.8188.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23785c712f9d4b45a9d221f52c263ec4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1_4 improved by 0.002 >= min_delta = 0.0. New best score: 0.821\n",
      "Epoch 19, global step 15720: 'val_f1_4' reached 0.82111 (best 0.82111), saving model to '/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models/frosty-morning-68-epoch=19-val_f1_4=0.8211.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e933c7e86fd3418cbe6269003209d654"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 16506: 'val_f1_4' reached 0.82001 (best 0.82111), saving model to '/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models/frosty-morning-68-epoch=20-val_f1_4=0.8200.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09ae88bc87d74b17811535fd6e985d22"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_f1_4 improved by 0.000 >= min_delta = 0.0. New best score: 0.821\n",
      "Epoch 21, global step 17292: 'val_f1_4' reached 0.82118 (best 0.82118), saving model to '/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models/frosty-morning-68-epoch=21-val_f1_4=0.8212.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "329ebc1740b54250899f172c8f814af6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 18078: 'val_f1_4' was not in top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f67c8ce5a1824c208ab75d91e3824f35"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 18864: 'val_f1_4' reached 0.82049 (best 0.82118), saving model to '/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models/frosty-morning-68-epoch=23-val_f1_4=0.8205.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dcc6b92f79d44d3881eca0588af6fdf3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_f1_4 did not improve in the last 3 records. Best score: 0.821. Signaling Trainer to stop.\n",
      "Epoch 24, global step 19650: 'val_f1_4' reached 0.82110 (best 0.82118), saving model to '/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models/frosty-morning-68-epoch=24-val_f1_4=0.8211.ckpt' as top 3\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=model, datamodule=hw2_dm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "param = HW2Params34(\"gpu\")\n",
    "wandb_logger.experiment.config.update(param.gethyperparameterdict())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "load = True\n",
    "if load:\n",
    "    savemodel = model.load_from_checkpoint(\n",
    "        '/home/orlando/PycharmProjects/nlp2022-homeworks/nlp2022-hw2/experiments/hw2models/frosty-morning-68-epoch=21-val_f1_4=0.8212.ckpt',\n",
    "        language=\"EN\", params=HW2Params34(\"gpu\"), eval_type=\"34\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(mainpath, \"model\", wandb_logger.experiment.name + \"_highest_ckpt.bkp\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}